{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac796108e8b54de9954ae222b9ba8c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/752 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71705bdd755040c8ba7b58a737403edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6139b3b6f344342b77aa05fdc705f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/66.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b991cb1ab044a8e86790ca19e51cc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627f7fc3c940479ba71bea3f021688f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5343f9c4b7e64091b5b1f307009c5f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/862M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21405845b1ae4cef8dea83e281f768fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "# os.environ[\"HF_TOKEN\"] = \"YOUR_HF_TOKEN\"\n",
    "\n",
    "# Initialize RAGMultiModalModel\n",
    "model = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-05 14:56:31--  https://arxiv.org/pdf/1706.03762\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.3.42, 151.101.131.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2215244 (2.1M) [application/pdf]\n",
      "Saving to: ‘1706.03762’\n",
      "\n",
      "1706.03762          100%[===================>]   2.11M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2024-09-05 14:56:32 (32.9 MB/s) - ‘1706.03762’ saved [2215244/2215244]\n",
      "\n",
      "mkdir: cannot create directory ‘docs’: File exists\n"
     ]
    }
   ],
   "source": [
    "# Let's get everyone's favourite paper in here\n",
    "!wget https://arxiv.org/pdf/1706.03762\n",
    "!mkdir docs\n",
    "!mv 1706.03762 docs/attention.pdf\n",
    "!cp -r docs/attention.pdf docs/attention_with_a_mustache.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwrite is on. Deleting existing index attention_index to build a new one.\n",
      "Indexing file: docs/attention.pdf\n",
      "Added page 1 of document 0 to index.\n",
      "Added page 2 of document 0 to index.\n",
      "Added page 3 of document 0 to index.\n",
      "Added page 4 of document 0 to index.\n",
      "Added page 5 of document 0 to index.\n",
      "Added page 6 of document 0 to index.\n",
      "Added page 7 of document 0 to index.\n",
      "Added page 8 of document 0 to index.\n",
      "Added page 9 of document 0 to index.\n",
      "Added page 10 of document 0 to index.\n",
      "Added page 11 of document 0 to index.\n",
      "Added page 12 of document 0 to index.\n",
      "Added page 13 of document 0 to index.\n",
      "Added page 14 of document 0 to index.\n",
      "Added page 15 of document 0 to index.\n",
      "Index exported to .byaldi/attention_index\n",
      "Indexing file: docs/attention_with_a_mustache.pdf\n",
      "Added page 1 of document 1 to index.\n",
      "Added page 2 of document 1 to index.\n",
      "Added page 3 of document 1 to index.\n",
      "Added page 4 of document 1 to index.\n",
      "Added page 5 of document 1 to index.\n",
      "Added page 6 of document 1 to index.\n",
      "Added page 7 of document 1 to index.\n",
      "Added page 8 of document 1 to index.\n",
      "Added page 9 of document 1 to index.\n",
      "Added page 10 of document 1 to index.\n",
      "Added page 11 of document 1 to index.\n",
      "Added page 12 of document 1 to index.\n",
      "Added page 13 of document 1 to index.\n",
      "Added page 14 of document 1 to index.\n",
      "Added page 15 of document 1 to index.\n",
      "Index exported to .byaldi/attention_index\n",
      "Index exported to .byaldi/attention_index\n",
      "Search results for 'what's the BLEU score of this new strange method?':\n",
      "Doc ID: 1, Page: 8, Score: 19.375\n",
      "Doc ID: 1, Page: 9, Score: 19.375\n",
      "Doc ID: 0, Page: 8, Score: 19.375\n",
      "Doc ID: 0, Page: 9, Score: 19.375\n",
      "Doc ID: 1, Page: 11, Score: 17.75\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test indexing\n",
    "index_name = \"attention_index\"\n",
    "model.index(\n",
    "    input_path=Path(\"docs/\"),\n",
    "    index_name=index_name,\n",
    "    store_collection_with_index=False,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# BLEU tables are on page 8 and 9. We've indexed the pdf and its evil mustached twin, so we should see similar scores occur twice for every relevant page.\n",
    "query = \"what's the BLEU score of this new strange method?\"\n",
    "results = model.search(query, k=5)\n",
    "\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "\n",
    "print(\"Test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.8 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model.search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'vidore/colpali-v1.2', 'full_document_collection': False, 'highest_doc_id': 1}\n",
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8cfef3127b4fcf96a22ed1ec277dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading adapter...\n",
      "Adapter name:  vidore/colpali-v1.2\n"
     ]
    }
   ],
   "source": [
    "# Let's load the index now, to ensure the results are still the same.\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "model = RAGMultiModalModel.from_index(\"attention_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for 'what's the BLEU score of this new strange method?':\n",
      "Doc ID: 1, Page: 8, Score: 19.375\n",
      "Doc ID: 1, Page: 9, Score: 19.375\n",
      "Doc ID: 0, Page: 8, Score: 19.375\n",
      "Doc ID: 0, Page: 9, Score: 19.375\n",
      "Doc ID: 1, Page: 11, Score: 17.75\n"
     ]
    }
   ],
   "source": [
    "results = model.search(query, k=5)\n",
    "\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8348433a1844561a4fe6a2300b0b54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwrite is on. Deleting existing index attention_index_with_collection to build a new one.\n",
      "Added page 1 of document 0 to index.\n",
      "Added page 2 of document 0 to index.\n",
      "Added page 3 of document 0 to index.\n",
      "Added page 4 of document 0 to index.\n",
      "Added page 5 of document 0 to index.\n",
      "Added page 6 of document 0 to index.\n",
      "Added page 7 of document 0 to index.\n",
      "Added page 8 of document 0 to index.\n",
      "Added page 9 of document 0 to index.\n",
      "Added page 10 of document 0 to index.\n",
      "Added page 11 of document 0 to index.\n",
      "Added page 12 of document 0 to index.\n",
      "Added page 13 of document 0 to index.\n",
      "Added page 14 of document 0 to index.\n",
      "Added page 15 of document 0 to index.\n",
      "Index exported to .byaldi/attention_index_with_collection\n",
      "Index exported to .byaldi/attention_index_with_collection\n",
      "Search results for 'How does the positional encoding thing work?':\n",
      "Doc ID: 0, Page: 6, Score: 18.875\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Base64 is unique!\n",
      "Doc ID: 0, Page: 3, Score: 18.625\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Base64 is unique!\n",
      "Doc ID: 0, Page: 9, Score: 17.5\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Base64 is unique!\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Let's see how it looks like with the collection stored with the index, for simpler VLM integration at the cost of memory/storage.\n",
    "from pathlib import Path\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "model = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")\n",
    "\n",
    "# Test having base64 in the collection for completely seamless RAG.\n",
    "pdf_path = Path(\"docs/attention.pdf\")\n",
    "\n",
    "# Test indexing\n",
    "index_name = \"attention_index_with_collection\"\n",
    "model.index(\n",
    "    input_path=pdf_path,\n",
    "    index_name=index_name,\n",
    "    store_collection_with_index=True,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Test searching\n",
    "# page 6 holds the answer\n",
    "query = \"How does the positional encoding thing work?\"\n",
    "results = model.search(query, k=3)\n",
    "\n",
    "print(f\"Search results for '{query}':\")\n",
    "base_64s = set()\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "    print(f\"Base64: {result.base64[:50]}...\")\n",
    "    assert result.base64 not in base_64s\n",
    "    print(\"Base64 is unique!\")\n",
    "    base_64s.add(result.base64)\n",
    "print(\"Test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 1 to index.\n",
      "Added page 2 of document 1 to index.\n",
      "Added page 3 of document 1 to index.\n",
      "Added page 4 of document 1 to index.\n",
      "Added page 5 of document 1 to index.\n",
      "Added page 6 of document 1 to index.\n",
      "Added page 7 of document 1 to index.\n",
      "Added page 8 of document 1 to index.\n",
      "Added page 9 of document 1 to index.\n",
      "Added page 10 of document 1 to index.\n",
      "Added page 11 of document 1 to index.\n",
      "Added page 12 of document 1 to index.\n",
      "Added page 13 of document 1 to index.\n",
      "Added page 14 of document 1 to index.\n",
      "Added page 15 of document 1 to index.\n",
      "Index exported to .byaldi/attention_index_with_collection\n"
     ]
    }
   ],
   "source": [
    "#  Now, let's add another document, which in this case is the same document, but we don't need to tell the model that!\n",
    "\n",
    "model.add_to_index(pdf_path, store_collection_with_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for 'How does the positional encoding thing work?':\n",
      "Doc ID: 1, Page: 6, Score: 18.875\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Doc ID: 0, Page: 6, Score: 18.875\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Doc ID: 0, Page: 3, Score: 18.625\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "results = model.search(query, k=3)\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "    print(f\"Base64: {result.base64[:50]}...\")\n",
    "print(\"Test completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
